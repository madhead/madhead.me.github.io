<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>kafka on madhead</title>
    <link>https://madhead.me/tags/kafka/</link>
    <description>Recent content in kafka on madhead</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Thu, 18 Jun 2020 09:00:00 +0300</lastBuildDate><atom:link href="https://madhead.me/tags/kafka/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Learning Kafka: Kafka Connect &#43; Wikipedia</title>
      <link>https://madhead.me/posts/kafka-connect-wikipedia/</link>
      <pubDate>Thu, 18 Jun 2020 09:00:00 +0300</pubDate>
      
      <guid>https://madhead.me/posts/kafka-connect-wikipedia/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;I’ve been developing backend software for almost 10 years already and never had a chance to work closely with &lt;a href=&#34;https://kafka.apache.org&#34;&gt;Apache Kafka&lt;/a&gt;.
After a couple of technical interviews recently I’ve realized that it’s a significant gap in my experience.
So, I’ve decided to learn it by playing with publicly available Wikipedia’s recent changes event stream.
Join me in this article, where I’ll be developing a &lt;a href=&#34;https://kafka.apache.org/documentation/#connect&#34;&gt;Kafka Connect&lt;/a&gt; application listening for the latest Wikipedia edits and storing them in a Kafka topic!
I’ll develop a &lt;a href=&#34;https://kafka.apache.org/documentation/streams&#34;&gt;Kafka Streams&lt;/a&gt; application processing this topic in one of the future articles, so stay tuned.&lt;/p&gt;
&lt;/div&gt;</description>
    </item>
    
  </channel>
</rss>
